{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpAcqd7nh3zd"
   },
   "source": [
    "# **Problem Formulation** \n",
    "We want to find and predict the **Reddit Fake Post Detection** given the other features .\n",
    "\n",
    "False information on the Internet has caused many social problems due to the raise of social network and its role in different domains such as politics. In this assignment, we are going to predict if a specific reddit post is fake news or not, by looking at its title.\n",
    "\n",
    "\n",
    "\n",
    "*   **Input** :- Comments as a text.\n",
    "\n",
    "The data is raw (contains various forms of words)\n",
    "*   **Output** :- Predected Faking for posts.\n",
    "\n",
    "\n",
    "*   **Data Mining Function** :- Manipulating ,analyzing , preprocessing the data. \n",
    "*   **Challenges** ▶ : \n",
    "    1.   Nan cells.\n",
    "    2.   Unused and unimportnat column.\n",
    "    3.   Convert the dtype.\n",
    "    4.   convert strings by One Hot encoding.\n",
    "    5.   Handling unbalanced data by over sampling\n",
    "*   **Impact** ▶ : Predicting the Fake posts that will lead to a successful social life.\n",
    "\n",
    "\n",
    "\n",
    "Copyrights 2022 Master of science - Queens University - by/Mahmoud Khorshed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20ee0d9a"
   },
   "source": [
    "# 1- import libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1AIj4g54zTG1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1003\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  const JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1003\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.1.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # statistical data visualization\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold,train_test_split,cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import classification_report,f1_score ,roc_auc_score\n",
    "import re\n",
    "\n",
    "#Grid Search\n",
    "from sklearn.preprocessing import StandardScaler , OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV ,RandomizedSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "#Models \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#NLP\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import holoviews as hv\n",
    "import nltk \n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# some seeting for pandas and hvplot\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 300\n",
    "pd.options.display.max_colwidth = 100\n",
    "np.set_printoptions(threshold=2000)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from bokeh.models import NumeralTickFormatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b415026b"
   },
   "source": [
    "## 1.2 - load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSdC6PZ9qmtC"
   },
   "source": [
    "### install kaggle and get token Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liw9fCdFd83L",
    "outputId": "b599e9dd-3b9b-45d3-9b92-82515619656c"
   },
   "outputs": [],
   "source": [
    "# # !pip install -q kaggle\n",
    "# !mkdir ~/.kaggle\n",
    "# from google.colab import files\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wL9cyw8eFs6",
    "outputId": "7f61430b-290a-4e5c-db10-d4c579073c64"
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c cisc-873-dm-f22-a3   #Download data of competition \"Fake_Reddit_Prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKCPk0UnrtNN"
   },
   "source": [
    " **read data from the *path***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oeEeAZ-0x9a",
    "outputId": "02db77c9-91bb-4a2d-e05d-5b9216641c8d"
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)  #to display all row with its data\n",
    "# pd.options.display.max_rows = 1000\n",
    "\n",
    "# Load Data\n",
    "\n",
    "# importing required modules\n",
    "# from zipfile import ZipFile\n",
    "  \n",
    "# # specifying the zip file name\n",
    "# file_name = \"cisc-873-dm-f22-a3.zip\"\n",
    "  \n",
    "# # opening the zip file in READ mode\n",
    "# with ZipFile(file_name, 'r') as zip:\n",
    "#     # printing all the contents of the zip file\n",
    "#     zip.printdir()\n",
    "  \n",
    "#     # extracting all the files\n",
    "#     print('Extracting all the files now...')\n",
    "#     zip.extractall()\n",
    "#     print('Done!')\n",
    "\n",
    "data=pd.read_csv('xy_train.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_FVt3oxXAIbI",
    "outputId": "170ef72a-13f9-443c-f65f-0970a6306ca4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265723</th>\n",
       "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284269</th>\n",
       "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207715</th>\n",
       "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551106</th>\n",
       "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8584</th>\n",
       "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text  \\\n",
       "id                                                                                                            \n",
       "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
       "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
       "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
       "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
       "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
       "\n",
       "        label  \n",
       "id             \n",
       "265723      0  \n",
       "284269      0  \n",
       "207715      0  \n",
       "551106      0  \n",
       "8584        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data=pd.read_csv('/content/xy_t/rain.csv',index_col='id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D7vqUMp42UR"
   },
   "source": [
    "# 2- Exploratory *Data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vYjlwgzz303"
   },
   "source": [
    "EDA explained using sample Data set:\n",
    "To share my understanding of the concept and techniques I know,I’ll take an example of Data of product rating data set which is available on Iwish.com Machine Learning Repository and try to catch hold of as many insights from the data set using EDA.\n",
    "To starts with,I imported necessary libraries (for this example pandas, numpy,matplotlib and seaborn) and loaded the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "s0RPWKVrMdzd",
    "outputId": "a923899f-8f61-467d-b2b4-f2923a7b0042"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265723</th>\n",
       "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284269</th>\n",
       "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207715</th>\n",
       "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551106</th>\n",
       "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8584</th>\n",
       "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text  \\\n",
       "id                                                                                                            \n",
       "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
       "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
       "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
       "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
       "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
       "\n",
       "        label  \n",
       "id             \n",
       "265723      0  \n",
       "284269      0  \n",
       "207715      0  \n",
       "551106      0  \n",
       "8584        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()  #TO check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txZ08p5nfNyt"
   },
   "source": [
    "**Get the shape of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8SFFtxjzpo3",
    "outputId": "43febaa7-3c3d-4b74-bd4b-bc7ef1aa029c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # print the shape of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eey2hcXZ0XYw"
   },
   "source": [
    "* Dataset comprises of 60000 observations and 1 Feature and 1 label .\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DACZTQYp0vgT",
    "outputId": "098c89c2-58e1-447b-ae89-278db7246f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60000 entries, 265723 to 34509\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    60000 non-null  object\n",
      " 1   label   60000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose=True,memory_usage=True,show_counts=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OHM5RMo09cf"
   },
   "source": [
    "\n",
    "\n",
    "*   Data has  float , objects and integer values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIsj9y0LLnll",
    "outputId": "ee4696d2-f415-4877-d0d6-ac429b263a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything missing?\n",
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQJ-Cc45LmgW"
   },
   "source": [
    "*   There are not any columns have null/missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku4rDWGX60j6"
   },
   "source": [
    "**Get the columns and check unique values data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFvWMEmJ68SK",
    "outputId": "9f7fbc25-6bf0-492d-9bb1-89ddab392b04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     59645\n",
       "label        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features=list(data.columns)\n",
    "\n",
    "# for col in range(len(features)):   \n",
    "#     count = len(data[features[col]].unique()) # printing unique values of each Feature\n",
    "#     print(\"Number of unique values in %s =\"%features[col],count)\n",
    "\n",
    "# Another Easy WAy to do that without any increase in complexity by For Loop\n",
    "\n",
    "data.nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27DkkZbCfYba"
   },
   "source": [
    "**Get the unique values of label  of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59u0HSHP5V6f",
    "outputId": "530d0c93-b323-40b1-b18f-fbabed70c5a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()  #how many unique values and what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAvFYBGa375x"
   },
   "source": [
    "* Target variable/Dependent variable is discrete and categorical in nature.\n",
    "* “label” score scale ranges [0,1,2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvcukFITwNpB",
    "outputId": "03d4a0a7-6357-4c2b-fb8c-4679406e0c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        32172\n",
       "1        27596\n",
       "2          232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['label']].value_counts() \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Hk2Uj3znD09i",
    "outputId": "50c11cee-3a1c-4f6f-9f9e-3ddfe5464986"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Count plot match\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.countplot(x=\"label\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRVmGhFXlxEV"
   },
   "source": [
    "It is clear that the data is almost balanced but there is an outlier \"2\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "voan58pWTV1l",
    "outputId": "8048594b-7822-458a-e59e-5d73feb16db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD7CAYAAABpJS8eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAASH0lEQVR4nO3db4ydZZnH8e9p7bognW6FmVDA0r7YXkTQdKWVFwhvIL4wZJWA4FKlK6FIgI3AKv4p+DcYQmQhBspmIQazjRjDpiSEFjeEhj+pBpsVRdDLXdK6QidMU5qUEkHamX1xntmcnk6Z58ycOefQ+/tJmsxz3/c593WS5jfPXOfM3I2JiQkkSUe/ef0uQJLUGwa+JBXCwJekQhj4klQIA1+SCvGefhdwBO8FVgOjwME+1yJJ7xbzgSXAL4G32icHNfBXA0/3uwhJepc6B3imfXBQA38UYO/eNxgf9/cENHiOP/449uzZ3+8ypEPMm9dg8eL3QZWh7QY18A8CjI9PGPgaWP7f1ACbshXum7aSVAgDX5IKYeBLUiFq9fAj4pvAJdXlo5l5U9v8SuB+YAh4Crg6Mw9ExFJgIzACJLAmM32nS5L6YNo7/Ig4H/g48HfASuDMiLiwbdlG4LrMXAE0gHXV+AZgQ2aeBmwHbulS3ZKkDtVp6YwC/5yZf8nMt4HfAUsnJyPiVOCYzPxFNfQA8OmIWACcCzzUOt6luiVJHZq2pZOZL0x+HRF/S7O1c3bLkpM49DOfo8ApwAnAvsw80DYuSeqD2p/Dj4jTgUeBL2fmf7dMzQNaP5DcAManGKcar+3444/rZLk0I2eccQYvvPDC9Atn4fTTT+e3v/3tnO4hTafum7ZnA/8BXJ+ZP2mbfpnm326YdCKwCxgDFkXE/Mw8WK3Z1Ulxe/bs95dbNOe2bv15x48ZGRlibGxfR4/Zvfv1jveROjFvXuMdb5TrvGn7AeBh4LIpwp7M/CPwZvVNAeBzwJaq3/80cGk1fjmwpaPqJUldU+cO/0vAXwP/EhGTY/8K/D3wjczcDqwB7ouIIeC/gB9U664BfhQRNwP/C/xDF2uXJHWgMaCHmC8DdtjS0aCaSUtHmmstLZ3lwM7D5ntdkCSpPwx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SClH3TNshYBtwQWbubBlfCTzQsnQY2JuZZ0TEWuA24NVq7tHMXN+FmiVJMzBt4EfEWcB9wIr2ucx8DlhZrTsWeBa4uppeBdyYmQ92qVZJ0izUaemsA64Fdk2z7mvAk5n5THW9GlgbEc9HxMaIWDyLOiVJszTtHX5mXgnQcoD5YSJiEXAV8KGW4VHg+zRbQd8D7qZ52Hlt1dmM0kAaHl7Y7xKkjtTq4dfwWeDhzBybHMjMCye/jojbgZc6fVIPMdcg27379X6XIB2i5RDzqee7tM+ngJ9MXkTEooi4oWW+ARzo0l6SpBmYdeBHRAM4E/h5y/B+4KbqDV+A64BNs91LkjRzMwr8iNgcEauqy2HgL5n55uR8Zh4ELgHujYjf0fyGcNNsi5UkzVxjYmIge+TLgB328DWoRkaGGBvb1+8ypEO09PCXAzsPm+91QZKk/jDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKkStQ8wjYgjYBlyQmTvb5r4JXAHsrYbuy8x7ImIpsBEYARJYk5n7u1W4JKkz097hV+fSPgOsOMKSVcBnMnNl9e+eanwDsCEzTwO2A7d0o2BJ0szUucNfB1wL/PsR5lcBX4+IU4GngC8BB4FzgU9Vax4AngS+MotaJUmzMG3gZ+aVABFx2FxEHAf8Cvgy8D80g/0W4G5gX2YeqJaOAqd0Wlx1NqM0kIaHF/a7BKkjtXr4R1L15D8xeR0RdwA/pNnOaT99fLzT5/cQcw2y3btf73cJ0iFaDjGfen42Tx4RSyPiipahBvA2MAYsioj51fgSYNds9pIkzc5sP5b5Z+D2iFgeEQ2avf5Nmfk28DRwabXucmDLLPeSJM3CjAI/IjZHxKrM3A18AXiE5kcvG8Ad1bJrgKsi4kXgHODmLtQrSZqhxsTEQPbIlwE77OFrUI2MDDE2tq/fZUiHaOnhLwd2Hjbf64IkSf1h4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQtQ60zYihoBtwAWZubNt7pPAt2kefrID+Hxm7o2ItcBtwKvV0kczc323CpckdWbawI+Is4D7gBVTzA0B9wKrM/OViPgO8C3gi8Aq4MbMfLCrFUuSZqROS2cdzbNqpzqEfAFwbWa+Ul3/Blhafb0aWBsRz0fExohYPOtqJUkzNm3gZ+aVmfn0Eeb2ZOYmgIg4Bvgq8HA1PQp8F/gw8Cfg7m4ULEmamVo9/OlExCJgE/DrzPwRQGZe2DJ/O/BSp89bnc0oDaTh4YX9LkHqyKwDPyKWAD8DngBuqMYWAVdk5p3VsgZwoNPn9hBzDbLdu1/vdwnSIVoOMZ96fjZPHhHzgUeAn2bm9Zk5mc77gZuqN3wBrqP5E4AkqU9mdIcfEZuBbwAfAD4CvCciLq6mt2fmlRFxCXBv1dv/A3B5NwqWJM1MY2JiIFsmy4AdtnQ0qEZGhhgb29fvMqRDtLR0lgM7D5vvdUGSpP4w8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSpErROvImII2AZckJk72+ZWAvcDQ8BTwNWZeSAilgIbgREggTWZub97pUuSOjHtHX51Lu0zwIojLNkIXJeZK2geVr6uGt8AbMjM04DtwC2zL1eSNFN1WjrrgGuBXe0TEXEqcExm/qIaegD4dEQsAM4FHmodn22xkqSZm7alk5lXAkTEVNMnAaMt16PAKcAJwL7MPNA2Lknqk1o9/HcwD2g9ZbwBjE8xTjXekeowXqm297///ezdu7cne42MDM3p8y9evJjXXnttTvdQWWYb+C8DS1quT6TZ+hkDFkXE/Mw8WK05rCU0nT179jM+3v59QzqyvXv3Mja2b873GR5eyO7dr8/pHiMjQ3O+h44u8+Y13vFGeVYfy8zMPwJvRsTZ1dDngC2Z+TbwNHBpNX45sGU2e0mSZmdGgR8RmyNiVXW5BrgzIn4PHAf8oBq/BrgqIl4EzgFunm2xkqSZa0xMDGTLZBmww5aOOjUyMnRUtXR68Vp09Ghp6SwHdh423+uCJEn9YeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUiFpn2kbEZTRPrFoA3JWZ97TMrQQeaFk+DOzNzDMiYi1wG/BqNfdoZq7vQt2SpA5NG/gRcTJwK3Am8BawLSK2ZuaLAJn5HLCyWnss8CxwdfXwVcCNmflg1yuXJHWkTkvnfOCJzHwtM98AHgIuPsLarwFPZuYz1fVqYG1EPB8RGyNi8exLliTNRJ2WzknAaMv1KPDR9kURsQi4CvhQ29rvA9uA7wF30zz0vJbqbEapI8PDC4+afXr1WlSGOoE/D2g9SbwBjE+x7rPAw5k5NjmQmRdOfh0RtwMvdVKch5hrJub6cHHozSHm0JvXoqNHyyHmU8/XeI6XgSUt1ycCu6ZY9yngJ5MXEbEoIm5omW8AB2rsJ0maA3UC/3HgvIgYrt6UvQh4rHVBRDRovqn785bh/cBNEXFWdX0dsGn2JUuSZmLawM/MV4D1wFbgOeDHmflsRGyOiFXVsmHgL5n5ZsvjDgKXAPdGxO9ofkO4qcv1S5JqakxMDGSPfBmwwx6+OjUyMsTY2L4536cXPfxevRYdPVp6+MuBnYfN97ogSVJ/GPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRB1zrQlIi4DbgYWAHdl5j1t898ErgD2VkP3ZeY9EbEU2AiMAAmsycz93SpeklTftHf4EXEycCvwMWAlcFVEfLBt2SrgM5m5svo3+Q1hA7AhM08DtgO3dK1ySVJH6tzhnw88kZmvAUTEQ8DFwHda1qwCvh4RpwJPAV8CDgLn0jzcHOAB4EngK90oXJLUmTo9/JOA0ZbrUeCUyYuIOA74FfBl4CPA39C8kz8B2JeZB6Z6nCSpt+rc4c8DWg+WbQDjkxdVT/4Tk9cRcQfwQ5rtnPYDacfpQHU2o9SR4eGFR80+vXotKkOdwH8ZOKfl+kRg1+RF9cbs+Zn5w2qoAbwNjAGLImJ+Zh4ElrQ+rg4PMddMzPXh4tCbQ8yhN69FR4+WQ8ynnq/xHI8D50XEcEQcC1wEPNYy/2fg9ohYHhEN4FpgU2a+DTwNXFqtuxzYMoPXIEnqgmkDPzNfAdYDW4HngB9n5rMRsTkiVmXmbuALwCM0P3rZAO6oHn4NzU/1vEjzp4Sbu/8SJEl1NCYmBrJlsgzYYUtHnRoZGWJsbN+c79OLlk6vXouOHi0tneXAzsPme12QJKk/DHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKUedMWyLiMpqnVS0A7srMe9rmPwl8m+ZpVzuAz2fm3ohYC9wGvFotfTQz13ereElSfdMGfkScDNwKnAm8BWyLiK2Z+WI1PwTcC6zOzFci4jvAt4AvAquAGzPzwTmqX5JUU52WzvnAE5n5Wma+ATwEXNwyvwC4tjr7FuA3wNLq69XA2oh4PiI2RsTibhUuSepMncA/CRhtuR4FTpm8yMw9mbkJICKOAb4KPNyy9rvAh4E/AXfPvmRJ0kzU6eHPA1pPEm8A4+2LImIRsAn4dWb+CCAzL2yZvx14qZPiqsN4pY4MDy88avbp1WtRGeoE/svAOS3XJwK7WhdExBLgZ8ATwA3V2CLgisy8s1rWAA50UtyePfsZH5+YfqHUYvfu1+d8j+HhhT3Zpxd76Ogxb17jHW+U67R0HgfOi4jhiDgWuAh4bHIyIuYDjwA/zczrM3MyofcDN0XEWdX1dTR/ApAk9cG0d/jVJ2/WA1uBvwLuz8xnI2Iz8A3gA8BHgPdExOSbudsz88qIuAS4t+rt/wG4fE5ehSRpWo2JiYFsmSwDdtjSUadGRoYYG9s35/v0oqXTq9eio0dLS2c5sPOw+V4XJEnqDwNfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQtQ505aIuAy4GVgA3JWZ97TNrwTuB4aAp4CrM/NARCwFNgIjQAJrMnN/98qXJNU17R1+RJwM3Ap8DFgJXBURH2xbthG4LjNX0DysfF01vgHYkJmnAduBW7pUtySpQ3VaOucDT2Tma5n5BvAQMHl2LRFxKnBMZv6iGnoA+HRELADOrdb//3iX6pYkdahOS+ckYLTlehT46DTzpwAnAPsy80DbeG3V2YxSbVv+6Txe/7d/nPN95vY026b/vP7jDA8v7MFOKkWdwJ8HtJ4k3gDGa8y3j9P2uGl5iLk6deYtm3qyTy8OMV8Jc76Hji4th5hPPV/jOV4GlrRcnwjsqjE/BiyKiPnV+JK2x0mSeqhO4D8OnBcRwxFxLHAR8NjkZGb+EXgzIs6uhj4HbMnMt4GngUur8cuBLV2rXJLUkWkDPzNfAdYDW4HngB9n5rMRsTkiVlXL1gB3RsTvgeOAH1Tj19D8VM+LwDk0P9opSeqDxsTEQPbIlwE77OFrUPWihy91qqWHvxzYedh8rwuSJPWHgS9JhTDwJakQtf6WTh/Mh2Y/ShpU/v/UoGn5Pzl/qvlBDfwlAIsXv6/fdUhH5G+Ca4AtAV5qHxzUT+m8F1hN888xHOxzLZL0bjGfZtj/EnirfXJQA1+S1GW+aStJhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEG9TdtpYEVEUPANuCCzNzZ53Kk2rzDlzoQEWcBzwAr+l2L1CkDX+rMOuBaPJ9Z70K2dKQOZOaVABHR71KkjnmHL0mFMPAlqRAGviQVwsCXpEL49/AlqRDe4UtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IK8X+mNMiCupYwugAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(data['label'])\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yT029PaV9G7"
   },
   "source": [
    "# 3- Preprocessing\n",
    "\n",
    "This function do many preprocssing steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Zh2sYv5SSND"
   },
   "source": [
    "## 1- remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ws10mi3bUihX",
    "outputId": "b751d7e2-cf62-44cb-fc82-75dda8aaa3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping outlier\n",
      "0    0.536200\n",
      "1    0.459933\n",
      "2    0.003867\n",
      "Name: label, dtype: float64\n",
      "After dropping outlier\n",
      "0    0.538281\n",
      "1    0.461719\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before dropping outlier\")\n",
    "print(data[\"label\"].value_counts(normalize=True))\n",
    "data.drop(data.loc[data[\"label\"]==2].index,inplace=True)\n",
    "print(\"After dropping outlier\")\n",
    "print(data[\"label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "YSr0xFwGAIbd",
    "outputId": "9b9c2b21-1925-4c54-f535-33e6d730ea0f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Count plot match\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.countplot(x=\"label\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS0ziJlGo_9p"
   },
   "source": [
    "## Function Clean_Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEEx9ulobwe4",
    "outputId": "8baaadb5-5b4d-4b8b-9186-7a6d9fb9d15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porter studi\n",
      "Lancster study\n",
      "Snowball studi\n",
      "Wall time: 44.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "# nltk.download('stem')\n",
    "#nltk.download('wordnet')\n",
    "\"\"\"\n",
    "  For ENGlish Language  PorterStammer or LancasterStammer\n",
    "  PorterStemmer uses Suffix Stripping ,\n",
    "  PorterStemmer is known for its simplicity and speed.\n",
    "\"\"\" \n",
    "from nltk.stem import PorterStemmer\n",
    "Porter = PorterStemmer()\n",
    "print(\"porter\",Porter.stem(\"Studying\"))\n",
    "\n",
    "\"\"\"\n",
    "  containing about 120 rules indexed by the last letter of a suffix.\n",
    "  LancasterStemmer is simple, but heavy stemming due to iterations and\n",
    "  over-stemming may occur. Over-stemming causes the stems to be not \n",
    "  linguistic, or they may have no meaning.\n",
    "\"\"\"\n",
    "from nltk.stem import LancasterStemmer\n",
    "Lancaster = LancasterStemmer()\n",
    "print(\"Lancster\",Lancaster.stem(\"Studying\"))\n",
    "\n",
    "#  SnowballStemmers is not only English stemmers:.\n",
    "#But it is improvement for Portal\n",
    "\n",
    "Snowball = SnowballStemmer(\"english\",ignore_stopwords=False) \n",
    "print(\"Snowball\",Snowball.stem(\"Studying\"))\n",
    "\n",
    "\"\"\"\n",
    " these words are filtered out from search queries because\n",
    "  they return a vast amount of unnecessary information.\n",
    "\"\"\"  \n",
    "stop_words = set(stopwords.words(\"english\"))  #get the stop words and set ( unique them)\n",
    "\n",
    "\"\"\"\n",
    "Lemmatization, unlike Stemming, reduces the inflected words properly\n",
    " ensuring that the root word belongs to the language.\n",
    " it is used where it is necessary to get valid words.\n",
    "            WordNet Lemmatizer\n",
    "\n",
    "\"\"\"\n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "\"\"\" \n",
    "the word ‘leaves’ without a POS tag would get lemmatized to\n",
    "the word ‘leaf’, but with a verb tag, its lemma would become ‘leave’.\n",
    "POS tagging is the task of assigning each word in a sentence the part of speech \n",
    "that it assumes in that sentence. The primary target of POS tagging is to\n",
    "identify the grammatical group of a given word: whether it is a noun,\n",
    "pronoun, adjective, verb, adverbs, etc. based on the context.\n",
    "\"\"\"\n",
    "#Tokenization is the process of segmenting running text into sentences and words.\n",
    "#In essence, it’s the task of cutting a text into pieces called tokens.\n",
    "#tokenizer separates the sentence into words\n",
    "\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               [Porter,Lancaster,Snowball]\n",
    "def clean_text(text,Stemmer=Snowball,Lemmatization=False, for_embedding=False):\n",
    "    \"\"\"\n",
    "    Arguments = \n",
    "    Stemmer = [Porter,Lancaster,Snowball]\n",
    "     steps:\n",
    "        - remove any html tags (< /br> often found)\n",
    "        - Keep only ASCII + European Chars and whitespace, no digits\n",
    "        - remove single letter chars\n",
    "        - convert all whitespaces (tabs etc.) to single wspace\n",
    "           if not for embedding (but e.g. tdf-idf):\n",
    "        - all lowercase\n",
    "        - remove stopwords, punctuation and stemm\n",
    "    Return clean text    \n",
    "    \"\"\"\n",
    "    # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
    "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
    "    RE_ASCII = re.compile(r\"[^A-Za-z]\", re.IGNORECASE)\n",
    "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
    "\n",
    "    if for_embedding:\n",
    "        # Keep punctuation\n",
    "        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
    "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
    "\n",
    "    text = re.sub(RE_TAGS, \" \", text)\n",
    "    text = re.sub(RE_ASCII, \" \", text)\n",
    "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
    "    text = re.sub(RE_WSPACE, \" \", text)\n",
    "\n",
    "    word_tokens = word_tokenize(text)    \n",
    "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
    "    if for_embedding:\n",
    "        # no stemming, lowering and punctuation / stop words removal\n",
    "        words_filtered = word_tokens\n",
    "    else:\n",
    "      if Lemmatization==False:\n",
    "        words_filtered = [\n",
    "            Stemmer.stem(word) for word in words_tokens_lower if word not in stop_words]\n",
    "      else:\n",
    "        words_filtered = [\n",
    "            wordnet.lemmatize(word, pos=\"v\") for word in words_tokens_lower if word not in stop_words]\n",
    "                    # parts-of-speech (POS) tagging.  v = Verbs >> (leaves = Leave) \n",
    "\n",
    "    text_clean = \" \".join(words_filtered)\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd5MNYlVhv0I"
   },
   "source": [
    "Evaluate Clean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6xrPtRfhvJi",
    "outputId": "ba279892-66f6-4352-f44f-28cb5b362cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59768, 2)\n",
      "(59768, 3)\n",
      "(59758, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "# Clean text\n",
    "data[\"text_clean\"] = data.loc[data[\"text\"].str.len() > 20, \"text\"] # get rows with more than 5 words, other will NAN\n",
    "data[\"text_clean\"] = data[\"text_clean\"].map(\n",
    "    lambda x: clean_text(x,Stemmer=Snowball,Lemmatization=False, for_embedding=False) if isinstance(x, str) else x # if x STR >> clean data by function\n",
    ")\n",
    "print(data.shape)\n",
    "# Drop when any of x missing\n",
    "data = data[(data[\"text_clean\"] != \"\") & (data[\"text_clean\"] != \"null\")]\n",
    "\n",
    "data = data.dropna(axis=\"index\", subset=[\"text\",\"label\",\"text_clean\"]).reset_index(drop=True)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJyxIbK2L7nF"
   },
   "source": [
    "# 4- Split + Train Models Without Random Search\n",
    "Thoughts :- To get the best model for this data\n",
    "\n",
    "By ***experimental*** : Logistic Regression - XGboosting - Neural Network \n",
    "are the best models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJmV1tDYRnbr"
   },
   "source": [
    "## **Two different text preprocessing techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOLBd5cmQDGn"
   },
   "source": [
    " ### **1-TFIDF vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "hxcojxUnQJGX"
   },
   "outputs": [],
   "source": [
    "TFvectorizer=TfidfVectorizer(ngram_range= (1, 3),\n",
    "                             max_df = 0.9,min_df = 10,\n",
    "                             analyzer= 'word',norm='l2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEXZfeP42N65"
   },
   "source": [
    "### **2-Count vectorizer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "D2W1de752V0N"
   },
   "outputs": [],
   "source": [
    "Ctvectorizer= CountVectorizer(analyzer='word', ngram_range=(1, 2),\n",
    "                              max_df = 0.9,min_df = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjD-SqHRR8hr"
   },
   "source": [
    "## **Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature creation and modelling in a single function\n",
    "X=data.drop(['label','text'],axis=1)\n",
    "y=data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "O02cqDAWMD_d",
    "outputId": "91cea5d0-1374-4c44-919d-a63c29dc11d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47806,)\n",
      "(47806, 8613)\n"
     ]
    }
   ],
   "source": [
    "#Split\n",
    "x_train, x_test, y_train, y_test =train_test_split(X['text_clean'],y,\n",
    "                                                   train_size = 0.80,\n",
    "                                                   stratify =y, random_state = 202)\n",
    "print(x_train.shape)\n",
    "x_train=TFvectorizer.fit_transform(x_train)\n",
    "x_test=TFvectorizer.transform(x_test)\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyq2Ny_AMoaL"
   },
   "source": [
    "## **Train Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at0NYZpunWze"
   },
   "source": [
    "### 1 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1aZbBrMmr-O",
    "outputId": "80cb728e-decb-44fd-f148-4fa09f820044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826092877516774\n",
      "Wall time: 630 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "\n",
    "clf_DT = DecisionTreeClassifier(max_depth=1000,criterion='entropy',max_features=700,min_samples_leaf=20) # you could try with GINI>> replace ('entropy') with ('gini') \n",
    "clf_DT.fit(x_train, y_train) \n",
    "pred_test = clf_DT.predict_proba(x_test)[:,1]\n",
    "print(roc_auc_score(y_test,pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OBGxxu6oX3E"
   },
   "source": [
    "### 2- AdaBoost Classifier with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LunhcNSPtvz7",
    "outputId": "9e228d5f-5c98-4764-abed-73f2ac0a7488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839968012372335\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier_ABC_GB = AdaBoostClassifier(DecisionTreeClassifier(max_depth=50,\n",
    "                                             max_features=100,min_samples_leaf=10,\n",
    "                                            ),algorithm= 'SAMME',\n",
    "                                       learning_rate= 0.082,n_estimators= 400)\n",
    "classifier_ABC_GB.fit(x_train, y_train) \n",
    "pred_test = classifier_ABC_GB.predict_proba(x_test)[:,1]\n",
    "print(roc_auc_score(y_test,pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WjXNfL6o1oz"
   },
   "source": [
    "### 3- AdaBoost with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGIAKy02oh5r",
    "outputId": "6bbb6d7e-fffa-4417-ee5b-41d05ec8817a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8695666936600769\n",
      "Wall time: 14min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier_ABC_RF = AdaBoostClassifier(RandomForestClassifier(n_estimators= 200,max_depth=40),algorithm= 'SAMME',\n",
    "                                       learning_rate= 0.082,n_estimators= 100)\n",
    "classifier_ABC_RF.fit(x_train, y_train) \n",
    "pred_test = classifier_ABC_RF.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(roc_auc_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDRHo_qB-DAR"
   },
   "source": [
    "### 4- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "K4uL6dhv8oSu",
    "outputId": "718f1213-cc41-4e5f-9ebf-48f5ccbe6377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8550121230934431\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "classifier_XGBC = XGBClassifier(use_label_encoder=False,n_estimators=400,\n",
    "                                max_depth=50,\n",
    "                                objective='binary:logistic',eval_metric='mlogloss')\n",
    "\n",
    "classifier_XGBC.fit(x_train, y_train) \n",
    "pred_test = classifier_XGBC.predict_proba(x_test)[:,1]\n",
    "print(roc_auc_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wsM_ZDEo-pr"
   },
   "source": [
    "### 5- Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZ9zXnE73zlJ",
    "outputId": "7423468e-81a2-4e6a-cfaa-458cbb80d346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86887632951887\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier_GBC = GradientBoostingClassifier(\n",
    "    n_estimators=500,max_depth=50,\n",
    "    max_features=500,min_samples_leaf=10,\n",
    "                                            )\n",
    "\n",
    "classifier_GBC.fit(x_train, y_train) \n",
    "pred_test = classifier_GBC.predict_proba(x_test)[:,1]\n",
    "print(roc_auc_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xzg1R35Kplcs"
   },
   "source": [
    "### 6- Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRb8ocI55aZZ",
    "outputId": "0e0ef64e-92ef-4144-84c3-830587f75faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8723981569596905\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier_neural_MLP = MLPClassifier(\n",
    "        random_state=123,\n",
    "        solver=\"adam\",\n",
    "        hidden_layer_sizes=(12, 12, 12),\n",
    "        activation=\"relu\",\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=1)\n",
    "classifier_neural_MLP.fit(x_train, y_train) \n",
    "pred_test = classifier_neural_MLP.predict_proba(x_test)[:,1]\n",
    "print(roc_auc_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9znVSJw8p1Q9"
   },
   "source": [
    "### 7- Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "URRE56i-6Ti5",
    "outputId": "990d35ca-e6eb-45d9-9492-121e41574c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8212775802382661\n",
      "Wall time: 8.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random forest \n",
    "\n",
    "classifier_RFC = RandomForestClassifier(n_estimators= 200,max_depth=40)\n",
    "classifier_RFC.fit(x_train, y_train) \n",
    "pred_test = classifier_RFC.predict_proba(x_test)[:,1]\n",
    "print(roc_auc_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9U07Oi08oSw"
   },
   "source": [
    "### 8- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-x1SYvc38oSw",
    "outputId": "38b594f3-be54-4196-8c38-d368d2c011ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8738309079494669\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression \n",
    "Log_Reg = LogisticRegression(solver='sag',C= 1,  #sag is slow 50 sec on Colab but score > 0.87\n",
    "                             penalty='l2' ,        #lbfgs is very fast  = .867\n",
    "                             max_iter=1000)\n",
    "Log_Reg.fit(x_train, y_train) \n",
    "pred_test = Log_Reg.predict_proba(x_test)[:,1]\n",
    "print(roc_auc_score(y_test,pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl1duc_m8oSw"
   },
   "source": [
    "### It is clear that the best models for this data are ( Logistic Regression - Neural Network - XG Boost - gradient boost):\n",
    "\n",
    "* AdaBoost with RandomForest is good but take much time not good for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os6DAvfRV3Ru"
   },
   "source": [
    "# 5-Trials\n",
    "## Training Model (Split - Pipeline) \n",
    "*5 trails*\n",
    "All with **validation set** (not cross-validation).\n",
    "\n",
    "We Will Cover both character-level vectorizer and word-level vectorizer in tuning .\n",
    "\n",
    "1- Random Search with Logistic Regression (TFIDF vectorizer)\n",
    "\n",
    "2-  Random Search with Logistic Regression. (Counter vectorizer)\n",
    "\n",
    "3- Random Search with Random Forest\n",
    "\n",
    "4-Random Search with XGBoost.\n",
    "\n",
    "5- Random Search with Neural Network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK9hgyRBAIbh"
   },
   "source": [
    "## At first \n",
    "\n",
    "When applying the fit method of the vectorizer in all dataset might introduce some data leakage. As principle,the model shouldn't see the test data. So to guarantee that your model will not see test data on the training fase, it should split first, vectorizer after.\n",
    "\n",
    "I will do Random Search with **4** Classifiers.\n",
    "\n",
    "1 Random Search for Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWkRdhJckBdG"
   },
   "source": [
    "1- Define Function For **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "kuAhh6lFkLbN"
   },
   "outputs": [],
   "source": [
    "def make_submission(model,Test_data):\n",
    "  \n",
    "  print(\"Test shape \",Test_data.shape)\n",
    "\n",
    "  Test_data[\"text_clean\"] = Test_data[\"text\"].map(\n",
    "      lambda x: clean_text(x,Stemmer=Snowball,Lemmatization=False, for_embedding=False) if isinstance(x, str) else x)\n",
    "  \n",
    "  if Test_data.shape[0] != 59151:\n",
    "      print(\"You can't upload because the file isn't equal with 59151 rows \")\n",
    "      print(f\"The difference is {59151-Test_data.shape[0]}\")\n",
    "  else :\n",
    "      print(\"Good ...!!! You can upload Now\")\n",
    "  print(\"Test shape after preprocessing\",Test_data.shape)\n",
    "  print(\"Null = \",Test_data.isnull().sum().sum())\n",
    "  submission = pd.DataFrame()\n",
    "  submission['id'] = Test_data.index\n",
    "  submission['label'] = model.predict_proba(Test_data['text_clean'])[:,1]\n",
    "  \n",
    "\n",
    "  return(submission.to_csv('Text_submission.csv', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTSS2LT4JlaP"
   },
   "source": [
    "2- **Load test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "K0U4YvncJcOa"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "X=data.drop(['label','text'],axis=1)\n",
    "y=data['label']\n",
    "#test\n",
    "X_Test=pd.read_csv(('x_test.csv'),index_col='id')  #Load test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4fCSNgSJpcq"
   },
   "source": [
    "3- **Splitting data for validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_52-jQAcHHLK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "# Further split the original training set to a train and a validation set\n",
    "x_train2, X_val, y_train2, y_val =train_test_split(X['text_clean'],y,\n",
    "                                                   train_size = 0.7,\n",
    "                                                   stratify = y,\n",
    "                                                   random_state = 2022)\n",
    "\n",
    "# Create a list where train data indices are -1 and validation data indices are 0\n",
    "\n",
    "split_index = [-1 if x in x_train2.index else 0 for x in X.index]\n",
    "# Use the list to create PredefinedSplit\n",
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W89UXSiOKFvN"
   },
   "source": [
    "4- Make **Pipeline** (vectorizer + model )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF_Mj5lxciCK"
   },
   "source": [
    "## 1- Random Search with **Logistic Regression (TFIDF vectorizer)**\n",
    "\n",
    "\n",
    "\n",
    "We can tune the hyperparameters (including different preprocessing configurations using Random Search with validation set).\n",
    "\n",
    "\n",
    "The best hyperparameters are :- \n",
    "**Score** =  0.8752343380738591\n",
    "\n",
    "**C'**:  1\n",
    "\n",
    " **penalty**': 'l2'\n",
    " \n",
    "  **solver**': 'lbfgs'\n",
    "\n",
    "**thoughts and observations for trial 1** :\n",
    "\n",
    "We could search for many hyperparameters in Logistic Regression and choose the best .\n",
    "\n",
    "**Plan for trial 2:**\n",
    "\n",
    "I Found Score = 87%, Then we could try another Hyperparameter with same classifier for example **Logistic Regression** but with **Counter vectorizer**\n",
    "  and search for best hyperparameters. \n",
    "  I guess that the accuracy will be high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "JMzpNJLaciCO"
   },
   "outputs": [],
   "source": [
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    #Hyperparameter for TFIDFVectorizer  \n",
    "    \"tfidf__ngram_range\": [(1, 2),(1,3)], # (1, 3)\n",
    "    \"tfidf__max_df\": [0.4,0.5,0.6],    #0.3,0.5,,0.9\n",
    "    \"tfidf__min_df\": [10],\n",
    "    \"tfidf__analyzer\":[\"char\",\"word\"],  #,\"char\"\n",
    "    \"tfidf__norm\":[\"l2\"],\n",
    "    \n",
    "#     HYPERparamets for LogReg\n",
    "    \"LOG__solver\":['lbfgs',\"sag\"],  #\"sag\", 'newton-cg','liblinear',\n",
    "    \"LOG__C\":[1,1e-1],     #1e-1,,1e1,1e2\n",
    "    \"LOG__penalty\":['l2'],\n",
    "\n",
    "}\n",
    "\n",
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()),(\"LOG\",LogisticRegression(random_state=2022,max_iter=5000))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPTnARI_GHan",
    "outputId": "0fa611a2-1f54-4da4-b82e-a30fde27017b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "best Parameters {'tfidf__norm': 'l2', 'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 10, 'tfidf__max_df': 0.5, 'tfidf__analyzer': 'word', 'LOG__solver': 'lbfgs', 'LOG__penalty': 'l2', 'LOG__C': 1}\n",
      "best score ROC_AUC 0.872004632813468\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe_LOG_TFIDF = RandomizedSearchCV(\n",
    "    pipe, params, n_jobs=-1,cv=pds,verbose=1 ,scoring=\"roc_auc\", n_iter=20)\n",
    "pipe_LOG_TFIDF.fit(X['text_clean'],y) #.values.astype('U')\n",
    "\n",
    "print('best Parameters {}'.format(pipe_LOG_TFIDF.best_params_))\n",
    "print('best score ROC_AUC {}'.format(pipe_LOG_TFIDF.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxU8g_4gEppu"
   },
   "source": [
    "##### **Make submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4tndstqqEpAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape  (59151, 1)\n",
      "Good ...!!! You can upload Now\n",
      "Test shape after preprocessing (59151, 2)\n",
      "Null =  0\n"
     ]
    }
   ],
   "source": [
    "model=pipe_LOG_TFIDF # for make submission\n",
    "make_submission(model,X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnW9gnSTA2Qg"
   },
   "source": [
    "## 2- Random Search with **Logistic Regression. (Counter vectorizer)**\n",
    "\n",
    "We can tune the hyperparameters (including different preprocessing configurations using Random Search with validation set).\n",
    "\n",
    "\n",
    "The best hyperparameters are :- \n",
    "**Score** = 0.83\n",
    "\n",
    "**C'**: 0.1\n",
    "\n",
    " **penalty**': 'l2'\n",
    " \n",
    "  **solver**': 'lbfgs'\n",
    "\n",
    "**thoughts and observations for trial 2** :\n",
    "I thought the score would be high but it lower than previous,It becomes 83% less than by -4\n",
    "\n",
    "**Plan for trial 3**\n",
    "\n",
    "So,I could try another classifier with another Hyperparameter for example **Random Forest**\n",
    "  and search for best hyperparameters. \n",
    "  I guess that the accuracy will be great because it depend on Decision tree with probabilites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "GzX5pozUA2Qh",
    "outputId": "10ac2a6a-f250-4167-a6b1-b68d1eddeb1a"
   },
   "outputs": [],
   "source": [
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    #Hyperparameter for CounterVectorizer  \n",
    "    \"CntVec__ngram_range\": [(2, 2),(1,3),(2,3)], # (1, 3)\n",
    "    \"CntVec__max_df\": [0.4,0.5,0.6],    #0.3,0.5,,0.9\n",
    "    \"CntVec__min_df\": [8,9,10],\n",
    "    \"CntVec__analyzer\":[\"char\",\"word\"],  #,\"char\"\n",
    "    \n",
    "    \n",
    "#     HYPERparamets for LogReg\n",
    "    \"LOG__solver\":['lbfgs',\"sag\"],  #\"sag\", 'newton-cg','liblinear',\n",
    "    \"LOG__C\":[1,1e-1],     #1e-1,,1e1,1e2\n",
    "    \"LOG__penalty\":['l2'],\n",
    "\n",
    "}\n",
    "\n",
    "pipe = Pipeline([(\"CntVec\", CountVectorizer()),(\"LOG\",LogisticRegression(random_state=2022,max_iter=5000))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "K8NjzM0NA2Qh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "best Parameters {'LOG__solver': 'lbfgs', 'LOG__penalty': 'l2', 'LOG__C': 0.1, 'CntVec__ngram_range': (1, 3), 'CntVec__min_df': 9, 'CntVec__max_df': 0.6, 'CntVec__analyzer': 'char'}\n",
      "best score ROC_AUC 0.830271494300785\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe_LOG_CNT = RandomizedSearchCV(\n",
    "    pipe, params, n_jobs=-1,cv=pds,verbose=1 ,scoring=\"roc_auc\", n_iter=10)\n",
    "pipe_LOG_CNT.fit(X['text_clean'],y) #.values.astype('U')\n",
    "\n",
    "print('best Parameters {}'.format(pipe_LOG_CNT.best_params_))\n",
    "print('best score ROC_AUC {}'.format(pipe_LOG_CNT.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lLHmS6vE8fQ"
   },
   "source": [
    "##### **Make submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "xprbac21E8fQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape  (59151, 2)\n",
      "Good ...!!! You can upload Now\n",
      "Test shape after preprocessing (59151, 2)\n",
      "Null =  0\n"
     ]
    }
   ],
   "source": [
    "model=pipe_LOG_CNT # for make submission\n",
    "make_submission(model,X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac0f5LIcf6n3"
   },
   "source": [
    "## 3- Random Search with  With **Random Forest**\n",
    "\n",
    "\n",
    "\n",
    "**best score**  = 0.81\n",
    "\n",
    "**best hyperparameters**\n",
    "\n",
    "\n",
    "  **max_depth**':  20\n",
    "\n",
    " \n",
    "  **n_estimators** : 400\n",
    "\n",
    "**thoughts and observations for trial 3** :\n",
    "\n",
    "The results wasn't the best for my thoughts because **Random Forest** is a great classifier, but it is still good.\n",
    "but i think it needs more tuning for more wide variaty of hyperparameters but my GPU doesn't help me as needed.\n",
    "\n",
    "  \n",
    "**Plan for trial 4**\n",
    "\n",
    "I could try another classifier with another Hyperparameter for example **XGboost**\n",
    "  and search for best hyperparameters. \n",
    "  I guess that the accuracy will be the greatest because it is extreme gradient boost.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "aCOMdLyoDG3N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 5 candidates, totalling 5 fits\n",
      "best Parameters {'tfidf__norm': 'l2', 'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 10, 'tfidf__max_df': 0.7, 'tfidf__analyzer': 'word', 'RF__n_estimators': 400, 'RF__max_depth': 20}\n",
      "best score ROC_AUC 0.8100621899952997\n",
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# here we specify the search space\n",
    "# `__` denotes an attribute of the preceeding name\n",
    "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    #Hyperparameter for TFIDFVectorizer  \n",
    "    \"tfidf__ngram_range\": [(1, 2)], # (1, 3)\n",
    "    \"tfidf__max_df\": [0.7,0.9],    #0.3,0.5,,0.9\n",
    "    \"tfidf__min_df\": [10],\n",
    "    \"tfidf__analyzer\":[\"word\",\"char\"],  #,\"char\"\n",
    "    \"tfidf__norm\":[\"l2\"],\n",
    "    \n",
    "#     HYPERparamets for GB\n",
    "    \"RF__n_estimators\":[200,400],\n",
    "    \"RF__max_depth\":[10,20],\n",
    "    \n",
    "    \n",
    " \n",
    "}\n",
    "\n",
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                 (\"RF\", RandomForestClassifier())])\n",
    "# i was using a tfidftransformer,without using a countvectorizer before it.\n",
    "# Instead, just  I used a tfidfvectorizer which does both in one go.\n",
    "\n",
    "pipe_RF = RandomizedSearchCV(\n",
    "    pipe, params, n_jobs=-1,cv=pds,verbose=1 ,scoring=\"roc_auc\", n_iter=5)\n",
    "pipe_RF.fit(X['text_clean'].values.astype('U'),y)\n",
    "\n",
    "print('best Parameters {}'.format(pipe_RF.best_params_))\n",
    "print('best score ROC_AUC {}'.format(pipe_RF.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEgfPgmMFAL2"
   },
   "source": [
    "##### **Make submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iryj8BJvFAL3"
   },
   "outputs": [],
   "source": [
    "model=pipe_GB # for make submission\n",
    "make_submission(model,X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faXG97YthiEL"
   },
   "source": [
    "## 4- Random Search with **XGBoost**\n",
    "\n",
    "**best score**  = 0.87545684\n",
    "\n",
    "we could try  with its hyperparameters\n",
    "\n",
    "**best hyperparameters**=\n",
    "\n",
    "\n",
    "**n_estimators**': 50\n",
    "\n",
    "**max_depth**': 100\n",
    "\n",
    "**learning_rate**':  0.03\n",
    "\n",
    "\n",
    "\n",
    "**thoughts and observations for trial 4** :\n",
    "\n",
    "I tried it out and it gives me result 87% similar to **Logistic Regreesion** but my computational resources couldn't run the random search with many hyperparameters .\n",
    "\n",
    "**Plan for trial 5**\n",
    "\n",
    "I could try another Hyperparameter with another classifier for example **Neural Network**\n",
    "  and search for best hyperparameters. \n",
    "  I guess that the accuracy will be perfect because it is deep learning,the state of the art for Machine Learning ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YI2QNSSpjuyz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 5 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# here we specify the search space\n",
    "# `__` denotes an attribute of the preceeding name\n",
    "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    #Hyperparameter for TFIDFVectorizer  \n",
    "    \"tfidf__ngram_range\": [(1, 2),(1,3)], # (1, 3)\n",
    "    \"tfidf__max_df\": [0.7,0.9],    #0.3,0.5,,0.9\n",
    "    \"tfidf__min_df\": [8,10],\n",
    "    \"tfidf__analyzer\":[\"word\"],  #,\"char\"\n",
    "    \"tfidf__norm\":[\"l2\"],\n",
    "    \n",
    "#     HYPERparamets for GB\n",
    "    \"XGB__n_estimators\":[20,50],\n",
    "    \"XGB__max_depth\":[6,10],\n",
    "    \"XGB__learning_rate\":[0.03,0.1],\n",
    "    }\n",
    "    \n",
    " \n",
    "    # objective='binary:logistic'\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                 (\"XGB\", XGBClassifier(use_label_encoder=False,\n",
    "                                      eval_metric='mlogloss'))])\n",
    "\n",
    "\n",
    "\n",
    "pipe_XGB = RandomizedSearchCV(\n",
    "    pipe, params, n_jobs=-1,cv=pds,verbose=1 ,scoring=\"roc_auc\", n_iter=5)\n",
    "pipe_XGB.fit(X['text_clean'].values.astype('U'),y)\n",
    "\n",
    "print('best Parameters {}'.format(pipe_XGB.best_params_))\n",
    "print('best score ROC_AUC {}'.format(pipe_XGB.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb3FfgQSGIRR"
   },
   "source": [
    "##### **Make submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjmpgLnoGIRS"
   },
   "outputs": [],
   "source": [
    "model=pipe_XGB # for make submission\n",
    "make_submission(model,Test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfnlKAsFHdAb"
   },
   "source": [
    "## 5- Random Search with **Neural Network**\n",
    "\n",
    "The best hyperparameters are :- \n",
    "**Score** = 0.868\n",
    "\n",
    "\n",
    "**'MLP__solver'**: 'adam'\n",
    "\n",
    "**'activation'** : 'tanh'\n",
    "\n",
    "\n",
    "**thoughts and observations for trial 5** :\n",
    "It gives another good results and it is simple ,It is suitable for fast deployment because it is optimized and learn fast . it chooces the Adam solver of-course because it the optimal optimizer until now.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "3a8c6HJuHdAc"
   },
   "outputs": [],
   "source": [
    "# define parameter space to test \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "params = {\n",
    "    #Hyperparameter for TFIDFVectorizer  \n",
    "    \"tfidf__ngram_range\": [(1, 2),(1,3)], # (1, 3)\n",
    "    \"tfidf__max_df\": [0.7,0.8],    #0.3,0.5,,0.9\n",
    "    \"tfidf__min_df\": [8,10],\n",
    "    \"tfidf__analyzer\":[\"char\",\"word\"],  #,\"char\"\n",
    "    \"tfidf__norm\":[\"l2\",\"l1\"],\n",
    "    \n",
    "#     HYPERparamets for LogReg\n",
    "    \"MLP__solver\":['adam','sgd'], \n",
    "    \"MLP__activation\":[\"relu\",\"tanh\"],     \n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "        \n",
    "\n",
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                 (\"MLP\",MLPClassifier(random_state=2022,\n",
    "                                      hidden_layer_sizes=(12, 12, 12),\n",
    "                                      early_stopping=True,\n",
    "                                      n_iter_no_change=1))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0SzDUbRHdAc",
    "outputId": "0fa611a2-1f54-4da4-b82e-a30fde27017b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 5 candidates, totalling 5 fits\n",
      "best Parameters {'tfidf__norm': 'l2', 'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 10, 'tfidf__max_df': 0.8, 'tfidf__analyzer': 'word', 'MLP__solver': 'adam', 'MLP__activation': 'tanh'}\n",
      "best score ROC_AUC 0.8685589396163849\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe_MLP = RandomizedSearchCV(\n",
    "    pipe, params, n_jobs=-1,cv=pds,verbose=1 ,scoring=\"roc_auc\", n_iter=5)\n",
    "pipe_MLP.fit(X['text_clean'],y) #.values.astype('U')\n",
    "\n",
    "print('best Parameters {}'.format(pipe_MLP.best_params_))\n",
    "print('best score ROC_AUC {}'.format(pipe_MLP.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68XrsEbIHdAc"
   },
   "source": [
    "##### **Make submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h99nQWzkHdAc"
   },
   "outputs": [],
   "source": [
    "model=pipe_MLP # for make submission\n",
    "make_submission(model,X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0RJjFQeusrn"
   },
   "source": [
    "# Finally the best model is **Logistic Regression** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1o6ifwTQK4N"
   },
   "source": [
    "# َQuestions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76BwssTEQOdE"
   },
   "source": [
    "**1-  What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?**\n",
    "\n",
    "\n",
    "* An n-gram model is a technique of counting sequences of ( characters or words) that allows us to support rich pattern discovery in text.\n",
    "\n",
    "* Character n-gram :     \n",
    "\n",
    "it is a sequence of characters  like (A - H - K)\n",
    "\n",
    "* word n-gram :     \n",
    "\n",
    "It is a sequence of words like (play - walk up )\n",
    "\n",
    "\n",
    " word n-gram suffer more for OOV\n",
    " \n",
    "Ref : \n",
    "STACC, OOVDensity and N-gram Saturation: Vicomtech’s Participation in the WMT2018Shared Task on Parallel Corpus Filtering\n",
    "1- https://aclanthology.org/W18-6473.pdf\n",
    "\n",
    "2- https://web.stanford.edu/~jurafsky/slp3/3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3rK58mMY-WN"
   },
   "source": [
    "**2- What is the difference between stop word removal and stemming? Are these techniques language-dependent?**\n",
    "\n",
    "* **stop word** :     \n",
    "\n",
    "They are a lot of vocabulary don't have any effect on the meaning and repeated,So we removed the from the text.\n",
    "\n",
    " these words are filtered out from search queries because\n",
    "  they return a vast amount of unnecessary information.\n",
    "\n",
    "* **Stemming** : \n",
    "\n",
    "it returns the word to its root ,a stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate”\n",
    "\n",
    "* They are language-dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVaIkjijY_91"
   },
   "source": [
    "**3-Is tokenization techniques language dependent? Why?**\n",
    "\n",
    "* No , Beacuse it split every word or character as type (string) independent of input languages .\n",
    "\n",
    "* Like Function ( **is.alpha()** ) return bool value if the string if totally alphabetic [A-Za-z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw7jpME0ZFAD"
   },
   "source": [
    "**4-What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?**\n",
    "\n",
    "**Count Vectorizers**\n",
    "\n",
    "Count Vectorizer is a way to convert a given set of strings into a frequency representation.\n",
    "\n",
    "Count Vectors can be helpful in understanding the type of text by the frequency of words in it. But its major disadvantages are:\n",
    "\n",
    "** Its inability in identifying more important and less important words for analysis.\n",
    "** It will just consider words that are abundant in a corpus as the most statistically significant word.\n",
    "** It also doesn't identify the relationships between words such as linguistic similarity between words.\n",
    "\n",
    "**TF-IDF:**\n",
    "\n",
    "TF-IDF means Term Frequency - Inverse Document Frequency. This is a statistic that is based on the frequency of a word in the corpus but it also provides a numerical representation of how important a word is for statistical analysis.\n",
    "\n",
    "TF-IDF is better than Count Vectorizers because it not only focuses on the frequency of words present in the corpus but also provides the importance of the words. We can then remove the words that are less important for analysis, hence making the model building less complex by reducing the input dimensions.\n",
    "\n",
    "It would not be able to use all n-grams, but we could select them with random search to get best score ."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gpAcqd7nh3zd",
    "20ee0d9a",
    "b415026b",
    "SSdC6PZ9qmtC",
    "3D7vqUMp42UR",
    "5Zh2sYv5SSND",
    "pOLBd5cmQDGn",
    "qjD-SqHRR8hr",
    "dyq2Ny_AMoaL",
    "at0NYZpunWze",
    "9OBGxxu6oX3E",
    "1WjXNfL6o1oz",
    "dDRHo_qB-DAR",
    "_wsM_ZDEo-pr",
    "_n-1IbJZe6CB",
    "Xzg1R35Kplcs",
    "9znVSJw8p1Q9",
    "B9U07Oi08oSw",
    "sl1duc_m8oSw",
    "KK9hgyRBAIbh",
    "sF_Mj5lxciCK",
    "FxU8g_4gEppu",
    "MnW9gnSTA2Qg",
    "3lLHmS6vE8fQ",
    "Ac0f5LIcf6n3",
    "bEgfPgmMFAL2",
    "faXG97YthiEL",
    "yb3FfgQSGIRR",
    "EfnlKAsFHdAb",
    "68XrsEbIHdAc",
    "qpzMVwK9ooLg",
    "m0RJjFQeusrn"
   ],
   "name": "Ass3_Fake_Reddit_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
